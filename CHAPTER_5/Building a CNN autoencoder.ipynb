{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808fb4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn \n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision \n",
    "from PIL import Image \n",
    "from catalyst import dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66377e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module): \n",
    "    def __init__(self): \n",
    "        super(ConvAutoencoder, self).__init__() \n",
    "        self.encoder = nn.Sequential( \n",
    "            nn.Conv2d(1, 16, 4), \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.Conv2d(16, 4, 4), \n",
    "            nn.ReLU(), \n",
    "            nn.AvgPool2d(9), \n",
    "        ) \n",
    "        self.decoder = nn.Sequential( \n",
    "            nn.ConvTranspose2d(4, 16, 5, stride=2), \n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(16, 4, 5, stride=2), \n",
    "            nn.ReLU(), \n",
    "            nn.ConvTranspose2d(4, 1, 4, stride=2), \n",
    "            nn.Sigmoid(), \n",
    "        ) \n",
    "\n",
    "    def forward(self, x): \n",
    "        bottleneck_feature = self.encoder(x) \n",
    "        reconstructed_x = self.decoder( \n",
    "          bottleneck_feature \n",
    "        ) \n",
    "        return reconstructed_x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3259019",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNISTImageTarget( \n",
    "    torchvision.datasets.FashionMNIST \n",
    "): \n",
    "    def __getitem__(self, index): \n",
    "        img = self.data[index]         \n",
    "        img = Image.fromarray( \n",
    "            img.numpy(), mode=\"L\" \n",
    "        )         \n",
    "        if self.transform is not None: \n",
    "            img = self.transform(img) \n",
    "        return img, img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63ba356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(image): \n",
    "    return torchvision.transforms.ToTensor()(image) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2bc329",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_fashion_mnist_data = FashionMNISTImageTarget( \n",
    "    'fashion_mnist/', download=True, train=True, transform=transform_image, \n",
    ") \n",
    "valid_fashion_mnist_data = FashionMNISTImageTarget( \n",
    "    'fashion_mnist/', download=True, train=False, transform=transform_image, \n",
    ") \n",
    "loaders = { \n",
    "    \"train\": DataLoader( \n",
    "        train_fashion_mnist_data, batch_size=32, shuffle=True \n",
    "    ), \n",
    "    \"valid\": DataLoader( \n",
    "        valid_fashion_mnist_data, batch_size=32 \n",
    "    ), \n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff53e2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45bd748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = dl.SupervisedRunner( \n",
    "    input_key=\"features\", output_key=\"scores\", target_key=\"targets\", loss_key=\"loss\" \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e85f27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_mlp( \n",
    "    trial_number, net, epochs, load_on_stage_start=False, best_or_last='last', verbose=False \n",
    "): \n",
    "    model = net \n",
    "    optimizer = optim.Adam( \n",
    "    model.parameters(), lr=0.02 \n",
    "    )     \n",
    "    checkpoint_logdir = \"logs/trial_{}_autoencoder\".format(trial_number) \n",
    "    runner.train( \n",
    "        model=model, \n",
    "        criterion=criterion, \n",
    "        optimizer=optimizer, \n",
    "        loaders=loaders, \n",
    "        num_epochs=epochs, \n",
    "        callbacks=[ \n",
    "            dl.CheckpointCallback( \n",
    "                logdir=checkpoint_logdir, \n",
    "                loader_key=\"valid\", \n",
    "                metric_key=\"loss\", \n",
    "                load_on_stage_end='best', \n",
    "            ) \n",
    "        ], \n",
    "        logdir=\"./logs\", \n",
    "        valid_loader=\"valid\", \n",
    "        valid_metric=\"loss\", \n",
    "        minimize_valid_metric=True, \n",
    "        verbose=verbose, \n",
    "    ) \n",
    "    with open(os.path.join(checkpoint_logdir, '_metrics.json'), 'r' ) as f: \n",
    "        metrics = json.load(f) \n",
    "    if best_or_last == 'last': \n",
    "        valid_loss = metrics['last']['_score_'] \n",
    "    else: \n",
    "        valid_loss = metrics['best']['valid']['loss'] \n",
    "    return valid_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c2951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dcek/anaconda3/envs/py310/lib/python3.10/site-packages/torch/nn/parallel/data_parallel.py:32: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c5b86ad6de743f48c46dc9688ea1791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/20 * Epoch (train):   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (1/20) loss: 0.06007776159048081 | loss/mean: 0.06007776159048081 | loss/std: 0.009008542275007882 | lr: 0.02 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb69bc193a2405094461c7d631d79ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1/20 * Epoch (valid):   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (1/20) loss: 0.05547902113199235 | loss/mean: 0.05547902113199235 | loss/std: 0.006020873103538906 | lr: 0.02 | momentum: 0.9\n",
      "* Epoch (1/20) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da187bf2d74249a38468d7716d7c190c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/20 * Epoch (train):   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (2/20) loss: 0.05518941624959322 | loss/mean: 0.05518941624959322 | loss/std: 0.0059645427433264115 | lr: 0.02 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfee709749bb4e62bbcf1cde21c76c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "2/20 * Epoch (valid):   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (2/20) loss: 0.05389353442192076 | loss/mean: 0.05389353442192076 | loss/std: 0.005731117690421474 | lr: 0.02 | momentum: 0.9\n",
      "* Epoch (2/20) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4344cacfd85b49c59afcf8337e3095d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/20 * Epoch (train):   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (3/20) loss: 0.049784021631876584 | loss/mean: 0.049784021631876584 | loss/std: 0.007977565519554957 | lr: 0.02 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0067c67bd1d492eaf6e5ca072d2ded4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "3/20 * Epoch (valid):   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (3/20) loss: 0.03953739957213402 | loss/mean: 0.03953739957213402 | loss/std: 0.004430564631887325 | lr: 0.02 | momentum: 0.9\n",
      "* Epoch (3/20) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80f30f7199d455385ae12c5b89cd876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/20 * Epoch (train):   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4/20) loss: 0.03854317022562028 | loss/mean: 0.03854317022562028 | loss/std: 0.003934854902322897 | lr: 0.02 | momentum: 0.9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a39780a7c2435aae74add8e262ea29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "4/20 * Epoch (valid):   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid (4/20) loss: 0.037654136556386955 | loss/mean: 0.037654136556386955 | loss/std: 0.004379289860023009 | lr: 0.02 | momentum: 0.9\n",
      "* Epoch (4/20) \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8127d13d60f7440cb22773327ef056a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5/20 * Epoch (train):   0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnn_autoencoder = ConvAutoencoder() \n",
    "best_valid_loss = train_and_evaluate_mlp( \n",
    "    0, cnn_autoencoder, 20, load_on_stage_start=False, best_or_last='last', verbose=True \n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8164c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = valid_fashion_mnist_data[0][0].numpy() \n",
    "predicted_image = cnn_autoencoder( \n",
    "    torch.unsqueeze(valid_fashion_mnist_data[0][0], 0) \n",
    ") \n",
    "predicted_image = predicted_image.detach().numpy( ).squeeze(0).squeeze(0) \n",
    "f, axarr = plt.subplots(2,1,  figsize=(5, 5)) \n",
    "axarr[0].imshow(predicted_image, cmap='gray') \n",
    "axarr[1].imshow(input_image.squeeze(0), cmap='gray') \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca34c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
